{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import sys\n",
    "import logging\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "import sklearn.svm\n",
    "import sklearn.linear_model\n",
    "import sklearn.ensemble\n",
    "import sklearn.pipeline\n",
    "\n",
    "sys.path.append(\"../../\")  # trick to import clairvoya from internal notebook directory\n",
    "import clairvoya.runbench\n",
    "import clairvoya.pulearning\n",
    "import clairvoya.voya_plotter\n",
    "import clairvoya.datasetup\n",
    "import cPickle as pickle\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "voya_logger = logging.getLogger('voya_notebook')\n",
    "voya_logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_num_pos = 100\n",
    "train_num_unlab = 1000\n",
    "\n",
    "test_num_all = 3000\n",
    "test_num_pos_frac = 0.5\n",
    "\n",
    "num_runs_per = 5\n",
    "\n",
    "# gamma_range = (0.1, 0.5, 0.8, )\n",
    "gamma_range = (0.01, 0.03, 0.05, 0.1, 0.2, 0.3, 0.4, 0.9, 0.8, 0.7, 0.6) # , \n",
    "\n",
    "# Distributions\n",
    "Gaussian1_mean = [0,0]\n",
    "Gaussian2_mean = [1,1]\n",
    "\n",
    "Gaussian1_cov = [[1, 0.5], [0.5, 1]]\n",
    "Gaussian2_cov = [[1, -0.5], [-0.5, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate Gaussian Functions\n",
    "Gaussian1 = lambda n_samp: np.random.multivariate_normal(Gaussian1_mean, Gaussian1_cov, n_samp)\n",
    "Gaussian2 = lambda n_samp: np.random.multivariate_normal(Gaussian2_mean, Gaussian2_cov, n_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_samples = 500\n",
    "plot_g1 = Gaussian1(plot_samples)\n",
    "plot_g2 = Gaussian2(plot_samples)\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "plt.scatter(plot_g1[:,0], plot_g1[:,1], c='green', label=\"Positive Distribution\")\n",
    "plt.scatter(plot_g2[:,0], plot_g2[:,1], c='red', label=\"Negative Distribution\")\n",
    "plt.title('Gaussian distributions')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_gaussian_features_array(Gaussian, num, label):\n",
    "    data = Gaussian(num)\n",
    "    label = np.ones(num) * label\n",
    "    x_1 = data[:,0]\n",
    "    x_2 = data[:,1]\n",
    "    \n",
    "    features_array = np.column_stack((label, label, x_1, x_2, x_1*x_2, x_1**2, x_2**2))\n",
    "    return features_array\n",
    "\n",
    "def generate_mixed_df(num_sample, frac_pos, global_label=None):\n",
    "    num_pos = int(num_sample*frac_pos)\n",
    "    num_neg = int(num_sample - num_pos)\n",
    "    \n",
    "    features_arr_pos = generate_gaussian_features_array(Gaussian1, num_pos, 1)\n",
    "    features_arr_neg = generate_gaussian_features_array(Gaussian2, num_neg, 0)\n",
    "    \n",
    "    features_arr = np.vstack((features_arr_pos, features_arr_neg))\n",
    "    mixed_df = pd.DataFrame(features_arr, columns=(\"fake_id\", \"label\", \"X_1\", \"X_2\", \"X_1 * X_2\", \"X_1**2\", \"X_2**2\"))\n",
    "    \n",
    "    if global_label is not None:\n",
    "        mixed_df['label'] = global_label\n",
    "    \n",
    "    return mixed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = generate_mixed_df(test_num_all, 0.5)\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(5,5))\n",
    "df[df[\"label\"]==1].plot(kind=\"scatter\", x=\"X_1\", y=\"X_2\", c='green', ax=ax1, label=\"Positive\")\n",
    "df[df[\"label\"]==0].plot(kind=\"scatter\", x=\"X_1\", y=\"X_2\", c='red', ax=ax1, label=\"Negative\")\n",
    "plt.title(\"Example Testing Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.value_counts(df[['label']].values.ravel()) # Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate test data set\n",
    "gamma = 0.5\n",
    "train_unlabeled = generate_mixed_df(train_num_unlab, gamma, global_label=0)\n",
    "train_positive = generate_mixed_df(train_num_pos, 1)\n",
    "train_df = train_positive.append(train_unlabeled, ignore_index=True)\n",
    "print pd.value_counts(train_df[['label']].values.ravel()) # Sanity Check\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df = generate_mixed_df(test_num_all, test_num_pos_frac)\n",
    "print pd.value_counts(test_df[['label']].values.ravel()) # Sanity Check\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuring the benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"out_path\": None,\n",
    "    \"num_cores\": 3,\n",
    "    \"verbosity\": 0,\n",
    "}\n",
    "\n",
    "# Classifiers\n",
    "LR_estimator = sklearn.linear_model.LogisticRegression()\n",
    "svm_estimator = sklearn.svm.SVC(kernel='linear', probability=True)\n",
    "rf_estimator = sklearn.ensemble.RandomForestClassifier(n_jobs=config[\"num_cores\"])\n",
    "\n",
    "LRPosOnly = sklearn.pipeline.Pipeline([\n",
    "    ('lr' , LR_estimator),\n",
    "    ('po', clairvoya.pulearning.PosOnly(LR_estimator)),\n",
    "])\n",
    "\n",
    "LRBagging = sklearn.pipeline.Pipeline([\n",
    "    ('lr' , LR_estimator),\n",
    "    ('po', clairvoya.pulearning.PUBagging(LR_estimator)),\n",
    "])\n",
    "\n",
    "RFBagging = sklearn.pipeline.Pipeline([\n",
    "    ('rf' , rf_estimator),\n",
    "    ('po', clairvoya.pulearning.PUBagging(rf_estimator)),\n",
    "]) \n",
    "\n",
    "# SVMBagging = sklearn.pipeline.Pipeline([\n",
    "#     ('svm' , svm_estimator),\n",
    "#     ('po', clairvoya.pulearning.PUBagging(LR_estimator)),\n",
    "# ]) \n",
    "\n",
    "# SVMPosOnly = sklearn.pipeline.Pipeline([\n",
    "#     ('svm' , svm_estimator),\n",
    "#     ('po', clairvoya.pulearning.PosOnly(svm_estimator)),\n",
    "# ])\n",
    "\n",
    "# SVMDoubleWeight = sklearn.pipeline.Pipeline([\n",
    "#     ('svm' , svm_estimator),\n",
    "#     ('dw', clairvoya.pulearning.PULearnByDoubleWeighting(svm_estimator)),\n",
    "# ])\n",
    "\n",
    "# LRDoubleWeight = sklearn.pipeline.Pipeline([\n",
    "#     ('lr' , LR_estimator),\n",
    "#     ('dw', clairvoya.pulearning.PULearnByDoubleWeighting(LR_estimator)),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_file = 'result_data/gaussian_test_results.csv'\n",
    "\n",
    "classifiers = {\n",
    "#     Bagging eventually breaks with too many open files error\n",
    "#     'LR_Bagging': LRBagging,\n",
    "#     'SVM_Bagging': SVMBagging,\n",
    "    'RF_Bagging': RFBagging,\n",
    "    \n",
    "    # PU\n",
    "#     'LR_PosOnly(E&N2008)': LRPosOnly,\n",
    "#     'SVM_PosOnly(E&N2008)': SVMPosOnly,  #Â Cant predict proba\n",
    "\n",
    "#     'SVM_DoubleWeight(E&N2008)': SVMDoubleWeight,\n",
    "#     'LR_DoubleWeight(E&N2008)': LRDoubleWeight,  # fit() got an unexpected keyword argument 'sample_weight'\n",
    "    \n",
    "    # Normal\n",
    "#     'Logistic Regression': sklearn.linear_model.LogisticRegression(),\n",
    "#     'Gradient Boosting': sklearn.ensemble.GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=2),\n",
    "#     'Random Forest': sklearn.ensemble.RandomForestClassifier(n_jobs=config[\"num_cores\"]),\n",
    "}\n",
    "\n",
    "classifiers_gridparameters = { # Gridsearch off\n",
    "    'LR_Bagging': {'po__n_estimators': [30, 100], 'po__max_samples': [0.1, 0.3, 0.7, 1.0],\n",
    "                   'lr__fit_intercept': [True], 'lr__C': [0.1, 0.3, 0.5, 0.7, 1.0]},\n",
    "\n",
    "    'SVM_Bagging': {'po__n_estimators': [30, 100], 'po__max_samples': [0.1, 0.3, 0.7, 1.0],},\n",
    "    'RF_Bagging': {'po__n_estimators': [30, 100], 'po__max_samples': [0.1, 0.3, 0.7, 1.0],\n",
    "                  \"rf__n_estimators\": [10, 30, 50, 70, 100], 'rf__max_depth': [1, 2, 3, 4, 5, 7, 10]},\n",
    "    \n",
    "    'SVM_PosOnly(E&N2008)' : {'po__hold_out_ratio': [0.02, 0.05, 0.1, 0.2, 0.3, 0.5],\n",
    "                               'svm__C': [0.1, 0.2, 0.3, 0.5, 0.7, 0.8, 1.0]},\n",
    "    \n",
    "    'LR_PosOnly(E&N2008)': {'po__hold_out_ratio': [0.02, 0.05, 0.1, 0.2, 0.3, 0.5],\n",
    "                           'lr__fit_intercept': [True], 'lr__C': [0.1, 0.3, 0.5, 0.7, 1.0]},\n",
    "\n",
    "    'SVM_DoubleWeight(E&N2008)': {'svm__C': [0.1, 0.2, 0.3, 0.5, 0.7, 0.8, 1.0]},\n",
    "    'LR_DoubleWeight(E&N2008)': {'lr__fit_intercept': [True], 'lr__C': [0.1, 0.3, 0.5, 0.7, 1.0]},\n",
    "\n",
    "    'Logistic Regression': {'fit_intercept': [True], 'C': [0.1, 0.3, 0.5, 0.7, 1.0]},\n",
    "    'Gradient Boosting': {\"n_estimators\": [10, 30, 50, 70, 100], 'learning_rate': [0.1, 0.3, 0.7, 1.0],\n",
    "                          'max_depth': [1, 2, 3, 4, 5, 7, 10]},\n",
    "\n",
    "    'Random Forest': {\"n_estimators\": [10, 30, 50, 70, 100], 'max_depth': [1, 2, 3, 4, 5, 7, 10]},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(save_file):\n",
    "    with open(save_file, 'wb') as f:\n",
    "        f.write('clf,auc,gamma\\n')\n",
    "\n",
    "auc_results = {clf_name:[] for clf_name in classifiers.keys()}\n",
    "for g_num, gamma in enumerate(gamma_range):\n",
    "    voya_logger.info('Running classifiers for gamma={} ({}/{})'.format(gamma, g_num, len(gamma_range)))\n",
    "    run_results = {clf_name:[] for clf_name in classifiers.keys()}\n",
    "    for i in xrange(num_runs_per):\n",
    "        train_unlabeled = generate_mixed_df(train_num_unlab, gamma, global_label=0)\n",
    "        train_positive = generate_mixed_df(train_num_pos, 1)\n",
    "        \n",
    "        train_df = train_positive.append(train_unlabeled, ignore_index=True)\n",
    "        test_df = generate_mixed_df(test_num_all, test_num_pos_frac)\n",
    "        \n",
    "        config.update({\"test_df\": test_df, \"train_df\": train_df,})\n",
    "\n",
    "        results_dict = clairvoya.runbench.run_benchmark(config, classifiers, classifiers_gridparameters)\n",
    "        \n",
    "        # Output\n",
    "        csv_output = []\n",
    "        for clf_name in classifiers.keys():\n",
    "            csv_output.append((clf_name, results_dict[clf_name]['auc_score'], gamma))\n",
    "            \n",
    "        with open(save_file, 'ab') as f:\n",
    "            csv_f = csv.writer(f)\n",
    "            csv_f.writerows(csv_output)\n",
    "            \n",
    "    for clf_name in classifiers.keys():\n",
    "        auc_results[clf_name].append(run_results[clf_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process results\n",
    "\n",
    "Note that this section can be ndone independantly (after imports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_df = pd.read_csv(save_file)\n",
    "results_table = results_df.groupby([\"clf\", \"gamma\"], as_index=False).agg(['mean', 'std', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colors = seaborn.color_palette(\"Set2\", 10)\n",
    "result_classifiers = results_df.clf.unique()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i, clf_name in enumerate(result_classifiers):\n",
    "    clf_results = results_table.ix[(clf_name)]\n",
    "    clf_gamma_range = clf_results.index\n",
    "    auc_mean = clf_results.auc[\"mean\"]\n",
    "    auc_std = clf_results.auc[\"std\"]\n",
    "    auc_count = clf_results.auc[\"count\"]\n",
    "    auc_std_err = auc_std / np.sqrt(auc_count)\n",
    "    \n",
    "    plt.errorbar(clf_gamma_range, auc_mean, yerr=auc_std_err, label=clf_name,\n",
    "                 c=colors[i], capthick=1)\n",
    "    plt.scatter(clf_gamma_range, auc_mean, c=colors[i], lw=0)\n",
    "    \n",
    "plt.ylabel('AUC Score')\n",
    "plt.xlabel('Frac Unlabelled Positives')\n",
    "plt.legend()\n",
    "\n",
    "title = \"Train P {}, U {}, Test {}, Testfrac {}\".format(\n",
    "    train_num_pos, train_num_unlab, test_num_all, test_num_pos_frac)\n",
    "plt.title(title)\n",
    "plt.savefig(title + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
